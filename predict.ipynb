{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './data/weather/', 'data_path': 'weather.csv', 'model_id': 'weather_96_96', 'model': 'Autoformer', 'data': 'custom', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 96, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 21, 'dec_in': 21, 'c_out': 21, 'd_model': 512, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
    "parser.add_argument('--model_id', type=str, required=True, default='weather_96_96', help='model id')\n",
    "parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
    "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=True, default='train', help='dataset type')\n",
    "parser.add_argument('--input_path', type=str, default='./data/weather/', help='input path of the data file')\n",
    "parser.add_argument('--target_path', type=str, default='weather.csv', help='target path of the data file')\n",
    "parser.add_argument('--input_index', type=str, default='./data/weather/', help='input index of the data file')\n",
    "parser.add_argument('--target_index', type=str, default='weather.csv', help='target index of the data file')\n",
    "# parser.add_argument('--features', type=str, default='M',\n",
    "#                     help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=24, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=24, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=48, help='prediction sequence length')\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--bucket_size', type=int, default=4, help='for Reformer')\n",
    "parser.add_argument('--n_hashes', type=int, default=4, help='for Reformer')\n",
    "parser.add_argument('--enc_in', type=int, default=21, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=21, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=21, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=3, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=2, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='Exp', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0', help='device ids of multile gpus')\n",
    "\n",
    "args = parser.parse_args(args = [\n",
    "            \"--is_training\", \"1\",\n",
    "            \"--input_path\", \"data/building-data-genome-project-2/data/processing/weather/Hog.csv\",\n",
    "            \"--target_path\", \"data/building-data-genome-project-2/data/processing/electricity/Hog.csv\",\n",
    "            \"--target_index\", \"Hog_education_Jordan\",\n",
    "            \"--input_index\", \"timestamp airTemperature dewTemperature windSpeed\",\n",
    "            \"--model_id\", \"weather_96_96\",\n",
    "            \"--model\", \"Autoformer\",\n",
    "            \"--data\", \"train\",\n",
    "            # \"--features\", \"M\",\n",
    "            \"--seq_len\", \"24\",\n",
    "            \"--label_len\", \"24\",\n",
    "            \"--pred_len\", \"48\",\n",
    "            \"--e_layers\", \"2\",\n",
    "            \"--d_layers\", \"1\",\n",
    "            \"--factor\", \"3\",\n",
    "            \"--enc_in\", \"4\",\n",
    "            \"--dec_in\", \"4\",\n",
    "            \"--c_out\", \"1\",\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"1\",\n",
    "            \"--train_epochs\", \"2\"\n",
    "        ])\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.dvices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "args.input_index = args.input_index.split()\n",
    "args.target_index = args.target_index.split()\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "Exp = Exp_Main\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        # setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        setting = '{}_{}_{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            # args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    # setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n",
    "    setting = '{}_{}_{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n",
    "                                                                                                    args.model,\n",
    "                                                                                                    args.data,\n",
    "                                                                                                #   args.features,\n",
    "                                                                                                    args.seq_len,\n",
    "                                                                                                    args.label_len,\n",
    "                                                                                                    args.pred_len,\n",
    "                                                                                                    args.d_model,\n",
    "                                                                                                    args.n_heads,\n",
    "                                                                                                    args.e_layers,\n",
    "                                                                                                    args.d_layers,\n",
    "                                                                                                    args.d_ff,\n",
    "                                                                                                    args.factor,\n",
    "                                                                                                    args.embed,\n",
    "                                                                                                    args.distil,\n",
    "                                                                                                    args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
